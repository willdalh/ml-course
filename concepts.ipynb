{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kr칝sjkurs i AI - Grunnleggende prinsipper\n",
    "\n",
    "## Kunstig intelligens er s친 mangt\n",
    "<img src=\"https://media.licdn.com/dms/image/D5612AQE4PAb7ReqhRg/article-cover_image-shrink_600_2000/0/1679715986172?e=2147483647&v=beta&t=LlQEO0Tf583irseJlj3G3BI2pvpJaLyGM_gxALuwB0E\">\n",
    "\n",
    "Venn-diagrammet viser at tre buzzwords vi er kjent med i dagligtalen faller inn under hverandre.\n",
    "- AI\n",
    "    - Ethvert system som utf칮rer en oppgave hvor menneskelig intelligens kreves faller under begrepet AI.\n",
    "    - Eksempler\n",
    "        - S칮kealgoritmer som A*\n",
    "        - Ekspertsystemer / regel-baserte systemer\n",
    "            - Best친r av regler som er lagd av mennesker\n",
    "        - Alt som faller inn under maskinl칝ring\n",
    "- Maskinl칝ring\n",
    "    - Et system/algoritme som bygger opp en form for kunnskap basert p친 data. Denne kunnskapen brukes s친 til 친 l칮se problemer. \n",
    "    - Implementasjonen best친r av to faser \n",
    "        - Trening\n",
    "        - Bruk av modellen (ogs친 kalt inference)\n",
    "    - Eksempler\n",
    "        - Beslutningstr칝r\n",
    "            - <img src=\"https://images.datacamp.com/image/upload/v1677504957/decision_tree_for_heart_attack_prevention_2140bd762d.png\" height=\"300px\">\n",
    "            Reglene konstrueres ved hjelp av en treningsalgoritme\n",
    "        - Alt som faller inn under dyp l칝ring\n",
    "- Dyp l칝ring\n",
    "    - Et system som bygger opp en form for kunnskap basert p친 data ved bruk av nevrale nettverk.\n",
    "    - Jobber p친 vektorer med numeriske verdier, og beregninger utf칮res vanligvis p친 GPUer.\n",
    "    - Eksempler\n",
    "        - Blir gjennomg친tt i kodebiten av denne notebooken.\n",
    "\n",
    "Det finnes en annen inndelig av AI som ogs친 brukes ofte:\n",
    "- Symbolsk AI\n",
    "    - AI hvor beslutningene skjer p친 grunnlag av regler som kan deles opp i _symboler_. \n",
    "    - Synonym med GOFAI (Good-Old Fashioned AI)\n",
    "    - Eksempler\n",
    "        - Regler som spesifiseres ved hjelp av et programmeringsspr친k, alts친 en algoritme.\n",
    "- Subsymbolsk AI\n",
    "    - AI hvor beslutningene skjer p친 grunnlag av regler som ikke kan direkte tolkes av mennesker\n",
    "    - Er mer matematisk jordet. \n",
    "    - Eksklusivt dyp l칝ring, alts친 bare den innerste gruppen i venn-diagrammet.\n",
    "\n",
    "    \n",
    "## Dyp l칝ring\n",
    "\n",
    "Venn-diagrammet er litt utdatert. Under _Deep Learning_ mangler det feks:\n",
    "- Transformers\n",
    "    - En arkitektur hovedsaklig for spr친kforst친else vi **garantert** kommer til 친 ta i bruk.\n",
    "- Diffusjonsmodeller\n",
    "    - En modell som de siste to 친rene har oppn친d bedre resultater enn Generative Adversarial Networks (GAN). Brukes for det meste p친 bildesyntese.\n",
    "\n",
    "- Hvorfor bryr vi oss mest om dyp l칝ring n친 (b친de i dette kurset og til daglig)?\n",
    "    - Flesteparten av modellene som imponerer oss best친r av dype nevrale nettverk.\n",
    "        - ChatGPT\n",
    "        - GPT-4\n",
    "        - Stable Diffusion\n",
    "        - Midjourney\n",
    "        - AlphaZero\n",
    "    - Tekniske ressurser er tilgjengelige for 친 realisere mye av teorien som ble funnet p친 50-tallet.\n",
    "\n",
    "## Former for maskinl칝ring\n",
    "- Supervised learning\n",
    "    - Man bruker data og beskrivelser av dataen til 친 trene opp en modell.\n",
    "- Unsupervised learning\n",
    "    - Man bruker bare selve dataen, og modellen finner m칮nstre som man etterp친 kan studere.\n",
    "- Reinforcement learning\n",
    "    - Man plasserer en modell i et milj칮 som den f친r utforske og samle inn data selv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Den tekniske biten - Hvordan ser det ut 친 jobbe med nevrale nettverk n친 til dags?\n",
    "Det er flere begreper innen maskinl칝ring som kastes rundt i diskusjoner. Ved 친 g친 gjennom denne delen vil man kunne se tydeligere hva som menes med begrepene. \n",
    "\n",
    "Instrukser for 친 kj칮re kodeceller:\n",
    "- VSCode og Google Colab\n",
    "    - Velg en celle og trykk p친 郊윒잺-knappen til venstre av cellen\n",
    "- Jupyter Notebook i nettleseren\n",
    "    - Velg en celle og trykk p친 郊윒잺-knappen i navigasjonsmenyen i toppen av vinduet. \n",
    "- Shortcut for alle nevnt over\n",
    "    - Velg en celle og trykk `CTRL-Enter`\n",
    "\n",
    "\n",
    "\n",
    "## Vektorer\n",
    "I maskinl칝ring er all data i form av vektorer.\n",
    "\n",
    "Vi begynner med Numpy, som er det mest brukte biblioteket for data science i Python. Biblioteket tilbyr kraftigere metoder for 친 h친ndtere native Python-lister."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensjoner og _shapes_\n",
    "Fra matematikken vet vi at en liste med feks. 3 tall definerer en vektor/punkt som lever i et tre-dimensjonalt rom. Dette ser slikt ut i Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [3, 2, 1] # Starting with a normal python list\n",
    "vector = np.array(data) # Creating a numpy array from it\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med Numpy-arrays er det flere operasjoner som kan gj칮res (som vi ogs친 til en grad vil forvente av native Python-arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Max value: {vector.max()}\")\n",
    "print(f\"Min value: {vector.min()}\")\n",
    "\n",
    "print(f\"Index of max element: {vector.argmax()}\")\n",
    "print(f\"Index of max element: {vector.argmin()}\")\n",
    "\n",
    "print(f\"Sum: {vector.sum()}\")\n",
    "\n",
    "print(f\"Sorted:  {np.sort(vector)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P친 lik linje har vi et 16-dimensjonalt punkt (som vi heller lager med tilfeldige tall):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_dim_vector = np.random.randint(low=1, high=10, size=(16))\n",
    "high_dim_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matematikken sier videre at en matrise er en rektangul칝r liste / tabell. For matriser definerer man antall rader og kolonner. Det er her Numpy begynner 친 divergere litt fra vanlige Python-arrays. \n",
    "\n",
    "Vi lager en $2 \\times 3$-matrise, alts친 med 2 rader og 3 kolonner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.random.randint(low=1, high=10, size=(2, 3))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er vi usikker p친 hvilken _shape_ matrisen har, kan vi sjekke det med `.shape` attributtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the matrix is {matrix.shape}\")\n",
    "rows, cols = matrix.shape\n",
    "print(f\"It has {rows} rows and {cols} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan g친 videre ved 친 legge til dybde p친 en matrise, og lage det som kalles en tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = np.random.randint(low=0, high=10, size=(2, 3, 4))\n",
    "print(f\"The shape of the tensor is {tensor.shape}\")\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensoren over best친r av 2 matriser som hver har 3 rader og 4 koloner.\n",
    "\n",
    "Min faglige erfaring tilsier at s칝rlig begrepene _vektor_ og _tensor_ er generelle, og beskriver bare en samling verdier strukturert med en vilk친rlig _shape_. Rent praktisk er de flerdimensjonale lister/arrays. I denne gjennomgangen vil begge begrepene brukes litt her og der.\n",
    "\n",
    "Her kommer det derfor et veiskille i hva man legger i begrepet _dimensjoner_ n친r man referer til en tensor:\n",
    "- Antall elementer til sammen i tensoren (matematisk riktig)\n",
    "- Antall elementer som ligger i resultatet av `.shape`-attributtet \n",
    "\n",
    "For 친 redusere forvirring kaller man ofte den f칮rste for antall _features_. Den andre kan vi kalle for shape-dimensjoner. \n",
    "\n",
    "Numpy-arrays er veldig fleksible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = tensor.reshape(2, 3*4) # Combine the rows and columns into one\n",
    "print(f\"Shape of the reshaped tensor: {reshaped.shape}\")\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvis det er en shape-dimensjon vi ikke har styr p친 og ofte varierer kan vi la Numpy regne det ut selv ved 친 spesifisere `-1` for **en** av posisjonene.\n",
    "\n",
    "Dette er veldig nyttig n친r vi 칮nsker 친 samle flere datapunkt i en tensor. Vi vet gjerne hvordan et datapunkt ser ut, feks et bilde vil ha en bestemt h칮yde og bredde og antall fargekanaler. Og disse verdiene vil v칝re felles for alle datapunkt i datasettet. Denne prosessen kalles for batching, og vi kommer tilbake til det senere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = tensor.reshape(-1, 3*4)\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N친r vi har flere _shape_-dimensjoner har vi muligheten til 친 spesifisere dimensjoner av interesse for noen av operasjonene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = np.random.randint(low=0, high=10, size=(2, 3))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Summing along rows: {tensor.sum(axis=0)}\")\n",
    "print(f\"Summing along columns: {tensor.sum(axis=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min values along rows: {tensor.min(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rammeverket PyTorch\n",
    "\n",
    "PyTorch er et av flere biblioteker som brukes til trening av dype nevrale nettverk. Det andre kjente alternativet er TensorFlow. Hva man velger avhenger mye av smak, men begge har sine fordeler og ulemper. Jeg liker PyTorch fordi mindre av treningsprosessen blir gjemt og man har mer frihet.\n",
    "PyTorch omfatter mye av den funksjonaliteten man finner i Numpy, men tilbyr metoder for trening og konstruksjon av nevrale nettverk. En `np.ndarray` er ekvivalent med en `torch.Tensor`. Derfor tar vi n친 med oss det vi har l칝rt om Numpy-arrays n친r vi studerer Pytorch-tensorer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(2, 2)\n",
    "print(tensor)\n",
    "print(f\"Tensor shape: {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det er to viktige funksjonaliteter `torch.Tensor` implementerer, som man ikke finner i Numpy-arrays:\n",
    "1. St칮tte for 친 flytte dataene mellom CPU og GPU (hvis installert p친 datamaskinen).\n",
    "2. Loggf칮ring av hvilke operasjoner som er gjort p친 tensoren (nyttiggj칮res under trening)\n",
    "\n",
    "Vi ser p친 det f칮rste punktet ved 친 lage en tensor og sjekke hvilken enhet den havner p친."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Default tensor location: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det andre punktet er loggf칮ring av operasjoner p친 tensorer. Dette skjer bare p친 tensorer hvor flagget `requires_grad` er aktivert, og tensorer som deltar i en operasjon med en annen tensor som har det aktivert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(2, 2, requires_grad=True)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor + 2\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor * 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor / 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan sjekke loggen for 친 se at operasjonene er dokumentert. \n",
    "\n",
    "**Merk**: Dette gj칮r vi for moro skyld. Det er ikke noe man gj칮r i praksis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = tensor.grad_fn\n",
    "while len(grad_fn.next_functions) != 0:\n",
    "    print(grad_fn)\n",
    "    grad_fn = grad_fn.next_functions[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppsett av nevrale nettverk med PyTorch\n",
    "Nevrale nettverk har vanligvis komplekse strukturer. Likevel best친r de av flere isolerte komponenter, og disse finner man i `torch.nn`. \n",
    "\n",
    "De fleste komponentene blir et s친kalt _lag_ i nettverket, mens andre komponenter anvendes p친 eksisterende lag (feks aktiveringsfunksjoner). \n",
    "\n",
    "Den enkleste er `torch.nn.Linear`, og setter opp et line칝rt lag. Matematisk gj칮r den en line칝r transformasjon fra et vektorrom til et annet. Feks kan den ta inn en vektor med 5 features, og outputte en vektor med 3 features:\n",
    "\n",
    "<img src=\"nn_5in_3out-cropped.svg\" width=\"500px\" height=\"auto\" alt=\"SVG Image\"  style=\"filter: invert(100%); \"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "layer = nn.Linear(in_features=5, out_features=3) # Construct layer\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.Tensor([[1, 2, 3, 4, 5]])\n",
    "print(f\"Input vector: {data}\")\n",
    "output = layer(data) # Feed data into layer\n",
    "print(f\"Output vector: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer.weight)\n",
    "print(f\"Weight shape: {layer.weight.shape}\\n\")\n",
    "\n",
    "print(layer.bias)\n",
    "print(f\"Bias shape: {layer.bias.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N친r man sender input-vektoren inn skjer f칮lgende operasjon (hvor `@` er matrisemultiplikasjon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data @ layer.weight.T + layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser fra resultatet over at det stemmer .\n",
    "\n",
    "\n",
    "Vektene og biaset utgj칮r til sammen **parametrene** for dette line칝re laget, og er verdiene som endres under trening. Hvordan disse er strukturert og brukes varierer for andre typer lag. Konvolusjonelle lag bruker en \"sliding window\"-mekanisme hvor de samme vektene multipliseres med forskjellige deler av et bilde. Da brukes vanligvis et mindre antall parametre. Til denne introduksjon holder vi oss derimot til line칝re lag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktiveringsfunksjoner\n",
    "\n",
    "Det line칝re laget utf칮rer en line칝r operasjon. Fleksibiliteten av nevrale nettverk kommer derimot av s친kalte _aktiveringsfunksjoner_ som utf칮rer ikke-line칝re operasjoner p친 data. Disse inneholder **vanligvis ikke** trenbare parametre. De enkleste opererer p친 hvert element individuelt, som feks Tanh. Vi ser p친 et en-dimensjonalt-case for 친 visualisere det enkelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Library for visualization\n",
    "tanh = nn.Tanh()\n",
    "assert not hasattr(tanh, \"weight\") # No learnable weights\n",
    "\n",
    "data = torch.linspace(start=-6, end=6, steps=100) # One-dimensional vector with 100 elements \n",
    "output = tanh(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "ax.plot(data, output)\n",
    "ax.set_xlabel(\"Input data\")\n",
    "ax.set_ylabel(\"Tanh Output\")\n",
    "\n",
    "# Add a grid\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et viktig poeng er at aktiveringsfunksjoner ikke modifiserer _shapen_ til tensoren. Dette kan demonstreres p친 en tensor med flere shape-dimensjoner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(30, 5, 15)\n",
    "print(f\"shape before activation function: {data.shape}\")\n",
    "data = tanh(data)\n",
    "shape2 = print(f\"shape after activation function: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En annen viktig er `nn.Softmax`, og brukes til 친 transformere en vektor til elementer som summeres til 1. \n",
    "\n",
    "Dette gj칮r den litt annerledes enn Tanh, siden vi m친 spesifisere en av shape-dimensjonene som skal summeres til 1.\n",
    "\n",
    "Passer fint som siste lag i et nettverk man 칮nsker skal modellere en sannsynlighetsfordeling (Total sannsynlighet av alle utfallene av en stokastisk variabel skal v칝re 1). Derfor er den veldig relevant for NLP, siden de fleste spr친kmodeller l칝rer seg en betinget sannsynlighetsfordeling over ord gitt tidligere tekst. \n",
    "\n",
    "For denne anledningen tar vi ogs친 i bruk `nn.functional`, som er et delbibliotek som tilbyr mange av komponentene tilstandsfrie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# data = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "data = torch.randn(3, 3)\n",
    "print(f\"Original data:\\n{data}\")\n",
    "data = F.softmax(data, dim=1)\n",
    "print(f\"Transformed data:\\n{data}\")\n",
    "print(f\"Summing individual batch elements:\\n{data.sum(dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifisering av sifre\n",
    "Vi skal sette opp et nevralt nettverk som er i stand til 친 klassifisere sifre. Til det trenger vi det lett tilgjengelige MNIST-datasettet. Dette lastes ned gjennom torchvision-biblioteket. Torchvision-biblioteket er et hjelpebibliotek som tilbyr verkt칮y for Computer Vision-oppgaver. \n",
    "\n",
    "Datasett kommer vanligvis i et r친-format, og m친 behandles for 친 tilpasse det oppgaven vi skal gj칮re. I dette tilfellet f친r vi PNG-bilder som m친 gj칮res om til tensorer. Vi normaliserer ogs친 bildene for 친 f친 [bedre resultater](https://developers.google.com/machine-learning/data-prep/transform/normalization). Behandlingen gj칮res med `torchvision.transforms`-biblioteket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Pipeline of processing operations\n",
    "image_processing = transforms.Compose([\n",
    "    transforms.ToTensor(), # Cast into torch.Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Pixel-values will range in [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='./data', train=True, transform=image_processing, download=True)\n",
    "test_dataset = MNIST(root='./data', train=False, transform=image_processing, download=True) # Test data for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I maskinl칝ring trener man flere epoker (iterasjoner) p친 samme datasettet. \n",
    "\n",
    "Hver epoke inneholder igjen flere iterasjoner som best친r av 친 oppdatere vektene p친 et lite subset av datasettet. Man kaller dette for en batch. Denne logikken oppn친r vi delvis gjennom `torch.utils.data.DataLoader`. Resten kommer n친r selve treningen skjer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32) # Iterable that provides 16 data samples each iteration\n",
    "\n",
    "data, labels = next(iter(train_loader)) # Retrieve a batch of data samples and labels for inspection purposes\n",
    "print(f\"Shape of data batch: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensoren inneholder 32 eksemplarer, 1 fargekanal (grayscale), 28 piksler i h칮yden, og 28 piksler i bredden.\n",
    "Vi kan visualisere et tilfeldig eksemplar fra hele datasettet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to easily visualize MNIST instances\n",
    "def visualize(tensor):\n",
    "    h, w = tensor.shape[-2:]\n",
    "    image = transforms.functional.resize((tensor+1)/2, (h*6, w*6), interpolation=transforms.InterpolationMode.NEAREST) # Upscaling for visual purposes\n",
    "    image = transforms.functional.to_pil_image(image)\n",
    "    return image\n",
    "\n",
    "import random\n",
    "rand_index = random.randint(0, len(train_dataset)-1)\n",
    "data_sample, label_sample = train_dataset[rand_index]\n",
    "\n",
    "print(f\"Shown below is the digit {label_sample}\")\n",
    "visualize(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og tensoren i seg selv ser slik ut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vi trenger et nettverk\n",
    "Alle lag i PyTorch arver fra `nn.Module`. Fra [dokumentasjonen](https://pytorch.org/docs/stable/generated/torch.nn.Module.html):\n",
    "\n",
    ">Base class for all neural network modules. \n",
    ">\n",
    ">Your models should also subclass this class.\n",
    ">\n",
    ">Modules can also contain other Modules, allowing to nest them in a tree structure.\n",
    "\n",
    "Trestrukturen som snakkes om er veldig nyttig. Endringer vi gj칮r p친 toppen av treet vil propageres ned til enkeltmodulene. Feks det 친 flytte parametrene over p친 en annen device.\n",
    "\n",
    "Vi husker det enkle line칝re laget og tanh-funksjonen. De arver nemlig fra `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer.__class__.__base__)\n",
    "print(tanh.__class__.__base__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=1*28*28, out_features=200) # Input features are the number of pixels, output features is arbitrary\n",
    "        self.layer2 = nn.Linear(in_features=200, out_features=42) # Arbitrary values\n",
    "        self.layer3 = nn.Linear(in_features=42, out_features=10) # 10 digits to differentiate between\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=1) # Softmax will be computed for each batch element separately \n",
    "\n",
    "    def logits(self, data):\n",
    "        flattened_data = torch.flatten(data, start_dim=1, end_dim=-1) # Flatten the tensor from shape (batch_size, 1, 28, 28) to shape (batch_size, 1 * 28 * 28)\n",
    "\n",
    "        out = self.layer1(flattened_data)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        out = self.layer2(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, data):\n",
    "        logits = self.logits(data)\n",
    "        return self.softmax(logits)\n",
    "    \n",
    "model = Model() # Initialize model\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modellen v친r implementerer to metoder. `logits` gir unnormaliserte verdier og vil brukes under trening. `forward` bruker `softmax` til 친 normalisere output fra `logits`, og tas i bruk under _inference_.\n",
    "\n",
    "Vi tester modellen p친 sifferet vi visualiserte tidligere. Men f칮rst m친 vi endre litt p친 _shapen_ til dette sifferet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_sample.shape)\n",
    "test_input = data_sample[None, ...] # [None, ...] adds a new shape dimension in the front\n",
    "print(test_input.shape)\n",
    "test_input = test_input.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_sample[None, ...]` lager en kopi av `data_sample` med en ny dimensjon lagt til.\n",
    "De fleste modulene i PyTorch forventer at input skal ha en batch-dimensjon, selv om batchen inneholder bare en instans (et bilde i dette tilfellet).\n",
    "\n",
    "Kodesnutten er veldig kryptisk. \n",
    "- PyTorch tolker indeksering med typen `None` som at en ny shape-dimensjon skal lages. \n",
    "- De etterf칮lgende `...` samler de resterende shape-dimensjonene. Dette er det samme som `data_sample[None, :, :, :]`.\n",
    "- `test_input` best친r av de n칮yaktige samme elementene, men _organisert_ p친 en annen m친te. \n",
    "\n",
    "En tilsvarende m친te 친 skrive det p친 er `data_sample.unsqueeze(dim=X)`. Denne setter inn en ny (tom) dimensjon ved den spesifiserte dimensjonen. P친 samme m친te kan man fjerne (tomme) dimensjoner med `data_sample.squeeze(dim=X)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.forward(test_input)\n",
    "print(out)\n",
    "print(f\"The untrained model predicts the digit to be {out.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening\n",
    "Vi ser fra resultatene at modellen ikke er i stand til 친 avgj칮re hvilket siffer inputten var. \n",
    "\n",
    "Vi har modellen og datasettet. Da er det to viktige ting som mangler for 친 kunne oppn친 en fungerende modell. \n",
    "- **En loss-funksjon som definerer objectivet**\n",
    "    - Vi 칮nsker at modellen skal gi h칮yest sannsynlighet p친 det rette sifret.\n",
    "    \n",
    "- **En algoritme som utf칮rer gradient descent, alts친 selve maskinl칝ringen**\n",
    "    - Denne algoritmen skal ta utgangspunkt i losset for 친 optimere parametrene.\n",
    "    - Man implementerer slike aldri selv, og finner dem heller gjennom `torch.optim`.\n",
    "\n",
    "#### Loss-funksjoner\n",
    "Loss-funksjoner sammenlikner en prediction og et target. Prediction er output fra modellen, og target er fasiten vi vet fra datasettet. \n",
    "Den enkleste er _Mean Squared Error (MSE)_, som kalkulerer gjennomsnittlig kvadrert avvik mellom tilsvarende elementer i hver tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(size=(3, 4, 5))\n",
    "b = torch.zeros(size=(3, 4, 5))\n",
    "loss = F.mse_loss(a, b)\n",
    "print(loss)\n",
    "\n",
    "a = torch.rand(size=(3, 4, 5))\n",
    "b = torch.rand(size=(3, 4, 5))\n",
    "loss = F.mse_loss(a, b)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent\n",
    "Helt fram til beregningen av et loss konstrueres det en s친kalt _computational graph_. Denne kan propageres bakover for 친 beregne gradienter (derav det kjente navnet [backpropagation](https://simple.wikipedia.org/wiki/Backpropagation) som brukes i alle nevrale nettverk idag).\n",
    "- Fra matematikken vet vi at gradienter peker i retning hvor verdien 칮ker mest i en flervariabel kurve. Beveger vi oss i motsatt retning vil verdien minske.\n",
    "- Learning rate (en skalar verdi) styrer hvor store stegene er. \n",
    "\n",
    "Figuren under viser loss-funksjonen kalkulert for forskjellige verdier av parametrene $\\theta_1$ og $\\theta_2$ til en modell. \n",
    "\n",
    "[<img src=\"https://zitaoshen.rbind.io/project/optimization/1-min-of-machine-learning-gradient-decent/featured_hubf6ae7b9a0510d717632b017746fdfc1_374655_720x0_resize_lanczos_2.png\">](https://zitaoshen.rbind.io/project/optimization/1-min-of-machine-learning-gradient-decent/)\n",
    "\n",
    "<!-- Oppdatering av vektene gj칮res da slikt:\n",
    "\n",
    "$\\boldsymbol{w} \\leftarrow \\underbrace{\\alpha}_{\\text{learning rate}}$ -->\n",
    "\n",
    "Selv om konkrete regler finnes for beregning av gradientene til vektene, er det sv칝rt kronglete 친 gj칮re manuelt. Derfor takker vi AI-gudene for bibliotek som PyTorch og Tensorflow som gj칮r denne prosessen s친 og si automatisk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tilbake til treningen av en siffer-gjenkjenneren\n",
    "Til loss-funksjonen bruker vi `nn.CrossEntropyLoss`. Den sammenlikner to sannsynlighetsfordelinger. Matematikken bak er ikke s친 viktig.\n",
    "\n",
    "Til gradient descent bruker vi bruker Adam, som st친r for _Adaptive Moment Estimation_. Her er heller ikke matematikken viktig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # Progress bar\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        for i, (data, labels) in enumerate(pbar):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model.logits(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, labels)\n",
    "            \n",
    "            loss.backward() # Propagate the computational graph and calculate gradients\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "\n",
    "            # pbar.set_postfix(loss=loss.cpu().item()) if i%40 == 0 else None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing av modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "correct = 0\n",
    "for data, labels in test_loader:\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    pred = model.forward(data)\n",
    "    correct += torch.sum(pred.argmax(dim=1) == labels)\n",
    "accuracy = correct/len(test_dataset)\n",
    "\n",
    "print(f\"The accuracy of the model on the test set is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.forward(test_input)\n",
    "print(out)\n",
    "print(f\"The trained model predicts the digit to be {out.argmax()}\")\n",
    "# plt.bar(torch.linspace(0, 9, 10).numpy(), out[0].cpu().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder\n",
    "\n",
    "For 친 komme litt inn i tankegangen om vektorrepresentasjoner av tekst (embeddings), ser vi p친 en arkitektur som kalles for AutoEncoder. \n",
    "\n",
    "<img src=\"autoencoder.png\" height=\"300px\">\n",
    "\n",
    "Den best친r av to komponenter:\n",
    "- Encoder\n",
    "    - En sekvens med line칝re lag som reduserer dimensjonaliteten.\n",
    "    - Ender opp med en vektor med veldig f친 dimensjoner kontra 784 fra r친data.\n",
    "- Decoder\n",
    "    - En sekvens med line칝re lag som rekonstruerer inputten fra den korte vektoren.\n",
    "\n",
    "Vi tar i bruk `nn.Sequential` for 친 lage sekvenser av lag som dataen flyter gjennom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=200, out_features=42),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=42, out_features=16),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "             nn.Linear(in_features=16, out_features=42),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(in_features=42, out_features=200),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(200, 28*28),\n",
    "             nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, data):\n",
    "        out = torch.flatten(data, start_dim=1, end_dim=-1)\n",
    "        out = self.encoder(out)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, data):\n",
    "        out = self.decoder(data)\n",
    "        return out.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.encode(data)\n",
    "        out = self.decode(out)\n",
    "        return out\n",
    "    \n",
    "autoencoder = AutoEncoder()\n",
    "autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        for i, (data, _) in enumerate(pbar): # no need for labels\n",
    "            data = data.to(device)\n",
    "            pred = autoencoder.forward(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, data)\n",
    "            \n",
    "            loss.backward() # Propagate the computational graph and calculate gradients\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "\n",
    "            pbar.set_postfix(loss=loss.cpu().item()) if i%40 == 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi studerer n친 hvordan modellen klarer 친 rekonstruere et siffer fra datasettet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = random.randint(0, len(train_dataset)-1)\n",
    "data_sample, label_sample = train_dataset[rand_index]\n",
    "\n",
    "visualize(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = autoencoder.encode(data_sample[None, ...].to(device)) # Add batch dimension\n",
    "encoding\n",
    "print(encoding.shape)\n",
    "print(encoding)\n",
    "visualize(encoding[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding = autoencoder.decode(encoding)\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ved 친 ha en flaskehals i midten av nettverket, har modellen l칝rt seg en lav-dimensjonell representasjon av sifrene.\n",
    "\n",
    "Det morsomme er at decoder-delen av nettverket kan anvendes som en generativ modell. Inputtet vil v칝re en vektor av lav dimensjon. Vi har ogs친 brukt `Tanh` som aktiveringsfunksjon p친 output fra encoderen, som betyr at decoderen alltid vil forvente tall som ligger i $\\langle-1, 1\\rangle$. \n",
    "\n",
    "Hvis vi generer en 16-dimensjonal vektor med tilfeldige tall, og bruker dette som input til decoderen, f친r vi et _syntetisk_ siffer som output. Den 16-dimensjonale vektoren vil i faglitteraturen kalles for en _latent_ representasjon av et siffer.\n",
    "\n",
    "Jeg skrev [masteroppgaven min](https://willdalh.github.io/thesis/thesis.pdf) om latente representasjoner i diffusjonsmodeller. Bare ta en titt 游땏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = (torch.rand(size=(1, 16))-0.5)*2\n",
    "decoding = autoencoder.decode(latent.to(device))\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultatene gjenspeiler den enkle arkitekturen som er valgt. Det er flere forbedringer man kan gj칮re p친 arkitekturen for 친 f친 mer lovende sifre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppvarming til NLP\n",
    "Bilder har en naturlig representasjon som vektorer/tensorer. Piksler som ligger ved siden av hverandre har relativt like verdier og man f친r fine overganger mellom. Tekst er strukturert p친 en litt mer rotete m친te, og virker mer abstrakt.\n",
    "\n",
    "N친 til dags distribueres modeller og kode gjennom en plattform som heter _Hugging Face_. Vi s칮rger f칮rst for at `transformers`-biblioteket som de drifter er lastet ned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "library_name = 'transformers'\n",
    "try:\n",
    "    importlib.import_module(library_name)\n",
    "    print(f\"{library_name} is already installed.\")\n",
    "except ImportError:\n",
    "    print(f\"{library_name} is not installed. Installing...\")\n",
    "    %pip install {library_name}\n",
    "    print(f\"{library_name} has been installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fleste NLP-pipeliner begynner med en tokenizer, som oversetter deler av en setning til IDer. Ulike modeller ledsager ulike tokenizers, derfor m친 vi spesifisere modell-navnet `bert-base-uncased`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi lager IDer av uttrykket \"Team Kamel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Team Kamel\", return_tensors=\"pt\")\n",
    "print(f\"IDs: {inputs['input_ids']}\")\n",
    "print(f\"Tokens from IDs: {tokenizer.convert_ids_to_tokens(inputs['input_ids'].squeeze())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disse IDene lar seg ikke godt gj칮re som input til et nevralt nettverk av to viktige grunner:\n",
    "- Tekst forekommer med ulike antall ord\n",
    "    - Nevrale nettverk tar inn samme antall features uansett. Endring av dette vil medf칮re at modellen m친 trenes p친 ny. \n",
    "- Hver ID forteller ikke mye om hva det representerer. To like ord kan f친 veldig ulike IDer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksempel p친 bruk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "text = \"Team Kamel will achieve [MASK] things\"\n",
    "unmasker(inputs=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veien videre\n",
    "Fra et teoretisk, historisk og etisk synspunkt dekker denne notebooken sv칝rt lite. Derfor anbefales _Maskiner som tenker_ av Inga Str칲mke. \n",
    "\n",
    "Ute i den store verdenen finnes det mange spennende implementasjoner p친 arkitekturer, og alle vil virke overveldende. Mitt beste tips er 친 starte med 친 leke mye med manipulering av tensorer og sm친 nettverksarkitekturer. F친 en god feeling p친 hva som virker og hvorfor det virker. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
