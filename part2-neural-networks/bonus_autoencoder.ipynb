{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "import os\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"Running in Google Colab, installing requirements...\")\n",
    "    # URL of the requirements file\n",
    "    requirements_url = \"https://raw.githubusercontent.com/willdalh/ml-course/main/requirements.txt\"\n",
    "\n",
    "    # Check if the requirements file already exists\n",
    "    if not os.path.exists('requirements.txt'):\n",
    "        # Download the requirements file\n",
    "        !wget {requirements_url}\n",
    "\n",
    "    # Install the requirements\n",
    "    !python -m pip install --user -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder\n",
    "\n",
    "AutoEncoder er en nettverksarkitektur som rekonstruerer input fra en lav-dimensjonell representasjon av input. Input er for eksempel pikslene p√• et bilde. Disse g√•r gjennom en serie nettverkslag som reduserer antall features, frem til man n√•r en flaskehals. Fra flaskehalsen skal modellen s√• gjenskape det som var i input. \n",
    "\n",
    "<img src=\"../res/autoencoder.png\" height=\"300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En AutoEncoder best√•r av to komponenter:\n",
    "- Encoder\n",
    "    - En sekvens med line√¶re lag som reduserer dimensjonaliteten.\n",
    "    - Ender opp med en vektor med veldig f√• dimensjoner kontra 784 fra r√•data.\n",
    "- Decoder\n",
    "    - En sekvens med line√¶re lag som rekonstruerer inputten fra den korte vektoren.\n",
    "\n",
    "Vi tar i bruk `nn.Sequential` for √• lage sekvenser av lag som dataen flyter gjennom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=200, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=200, out_features=42, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=42, out_features=32, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=42, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=42, out_features=200, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=200, out_features=784, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, bottleneck_size=16):\n",
    "        super().__init__()\n",
    "        self.bottleneck_size = bottleneck_size\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=200, out_features=42),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=42, out_features=bottleneck_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "             nn.Linear(in_features=bottleneck_size, out_features=42),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(in_features=42, out_features=200),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(200, 28*28),\n",
    "             nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, data):\n",
    "        out = torch.flatten(data, start_dim=1, end_dim=-1)\n",
    "        out = self.encoder(out)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, data):\n",
    "        out = self.decoder(data)\n",
    "        return out.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.encode(data)\n",
    "        out = self.decode(out)\n",
    "        return out\n",
    "    \n",
    "autoencoder = AutoEncoder(bottleneck_size=32)\n",
    "autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "# Pipeline of processing operations\n",
    "image_processing = transforms.Compose([\n",
    "    transforms.ToTensor(), # Cast into torch.Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Pixel-values will range in [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='../data', train=True, transform=image_processing, download=True)\n",
    "test_dataset = MNIST(root='../data', train=False, transform=image_processing, download=True) # Test data for later\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:07<00:00, 234.44batch/s]\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:07<00:00, 236.67batch/s]\n",
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:07<00:00, 236.41batch/s]\n",
      "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:08<00:00, 229.03batch/s]\n",
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:07<00:00, 241.03batch/s]\n",
      "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:07<00:00, 250.04batch/s]\n",
      "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:07<00:00, 237.00batch/s]\n",
      "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:07<00:00, 236.69batch/s]\n",
      "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:08<00:00, 226.93batch/s]\n",
      "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:08<00:00, 226.60batch/s]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        for i, (data, _) in enumerate(pbar): # no need for labels\n",
    "            data = data.to(device)\n",
    "            pred = autoencoder.forward(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, data)\n",
    "            \n",
    "            loss.backward() # Propagate the computational graph and calculate gradients\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi studerer n√• hvordan modellen klarer √• rekonstruere et siffer fra datasettet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAADT0lEQVR4Ae2bu2tVQRDGb9TgoxC0sLCysLBQsbAQFEGxERUUEQslpLQV1MJCiyD+ARa2KRQUCwOCilZiLCwlVcDCRmwUYiEoPuGbZi6bnbOzu8QMfCm+zJnH3j2/yXAel4xG/CEBEiABEiABEiABEiABEiABEiABEiABEiABEohBYGIlt7keH3YXegF6GPoWassaO7x6otxo716QaG+i69oX3IUlJqEL5nL7EJ1SObthc+oVkhUzOUy9UYch2jT1+4HtOXQt9Dz0BbSvhCHKjfZt/GhEor2JVk79XuxDpnuz2pPcsadTLw8SR1XmZ9izymObbL3Nxx8lUT8zuyIMUffU78SJ34DqeX8Kz+0Mlin4Z1T0LOzfymObYYhyo3Yj/VES9TOzKxxTL+/iZrHeAbXqM9jydu6b8mvzpD6AvZh4bAdbb/PxR0nUz8yuCEPUMfUPccp63l/Bcw76PQNkGv7TKvoY9hflKTHDEOVGS9rpySFRD62S3KKp34KVjqn1vsK+Cc3Nu6Rfxq8JOYD+gP5VnhKTrS+h5MkhUQ+tktwwRIumXp7BN6gTl7v6eeVJTanakQaqPGGIcqNV/TWKSNSAUxUqmvoFLP0LKgWnYL/PfKRc2bchujHJeZd4ShxsfQklTw6JemiV5IYhqm+9B07sCuKXoNuh8n4vLZOz/6MCH2Ffhcr7ARUsMsMQ5UaL+ulIIlEHrKJUx9Tr9Q7iYKt2KXsOtn5yn4bnHrRO2Po6bvkqEs2zqYuEIVp0h58yeJO64LmY+GfguZ/4vY4wRLlRb2uH8kl0iJA3Xjn1uY/R38v/RNIDqL7u52ptP1tv8/FHSdTPzK4IQ7Tb1J8AkOMKyyPYi8rTYoYhyo22tHm5WhJdjkqLr/K5Pv3Il3AdgX6C7oEuQduFrW9nOL4CiY7zaD8KQ7TDtV6m+5CCNg97SXnazTBEudH2Zo+vQKLjPNqPmqZebhTkP3Em1V4+wL4OfQKVb/xhVgpbXwkuW0aiWTSVgTBEm6Z+E+icSRhdg0fe4Mm39pz6BNJ/d4T5G+VGe/+tND3XS7HM+C21s9ew5Sp/B7a8z1cpbpOtdyMbKCDRAUDucBii7jNjAQmQAAmQAAmQAAmQAAmQwCom8A89iUJ8mry5mgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.visualize import visualize\n",
    "\n",
    "rand_index = torch.randint(0, len(test_dataset), (1,)).item()\n",
    "data_sample, label_sample = test_dataset[rand_index]\n",
    "\n",
    "visualize(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32])\n",
      "tensor([[-0.2683, -0.0901,  0.1352, -0.1284,  0.0341,  0.3011,  0.0492, -0.2790,\n",
      "          0.1196, -0.0837,  0.6147,  0.2447,  0.1780, -0.3403, -0.2461,  0.2670,\n",
      "         -0.0161, -0.0490, -0.0608, -0.1727, -0.2258,  0.3602, -0.1427,  0.1317,\n",
      "         -0.0567,  0.4090, -0.1206, -0.5092,  0.3619, -0.0741,  0.1640,  0.1304]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAGAMABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AMK1/wCPlPx/lW/p3/LT8P61Uvv+PyT8P5CtWw/4/Y/x/kas6n/yy/H+lcfqX/IQl/D+Qro7v/j1f8P51s+Cf+X7/tn/AOzVZ1T/AJCMv4fyFc3rn/IHn/4D/wChCuTg/i/Cu30P/kDwf8C/9CNZTfdqM1Tm/wBa1WfD/wDyHLf/AIF/6Ca2PE//AC6/8D/pUNh/x5R/j/M0aN/yFoP+Bf8AoJq34o/5dP8Agf8A7LXm+q/8hOb/AID/ACFeq6x/yC5v+A/+hCsXTf8Alr+H9auN96v/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAAAGCAAAAACwBs5yAAAAbUlEQVR4Ae3RIQqDABSAYTUvDlZkQY+waFreCQw7w044WbUIFpOgaSybFGSMfR5CBF/4eOnB4w/vwX9OjNnxyIQ9G174Zs6aIwseeGXLmV8OnHjjiyk/zPhkxQdLnrncjOwbZn9g7Xh7gbUL/AC6GhKc2FulrAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x6>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = autoencoder.encode(data_sample.unsqueeze(0).to(device)) # Add batch dimension\n",
    "encoding\n",
    "print(encoding.shape)\n",
    "print(encoding)\n",
    "visualize(encoding.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2683, -0.0901,  0.1352, -0.1284,  0.0341,  0.3011,  0.0492, -0.2790,\n",
       "          0.1196, -0.0837,  0.6147,  0.2447,  0.1780, -0.3403, -0.2461,  0.2670,\n",
       "         -0.0161, -0.0490, -0.0608, -0.1727, -0.2258,  0.3602, -0.1427,  0.1317,\n",
       "         -0.0567,  0.4090, -0.1206, -0.5092,  0.3619, -0.0741,  0.1640,  0.1304]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAAELUlEQVR4Ae2ay6tNURzHD9fb5SJEpGsgEYWklNRNGSgZ0B0Z3JFbJgYyZGLIQCkTSpkoIhn5A2Ri4JEBSSmvKK7HlfejPt/JOre7z1l7r9Vl1dfg47d/e6111v6s89uvc1st/7MBG7ABG7ABG7ABG7ABG7ABG7ABGyjVwKSJn3j4kX+iP35ydMt/3NATzb0ANprbaFiCDcfuod8sOAOOwF9QUJt5bAzB3fAyPAu/wSp46avMNM3baFNzVf2KMTql6gg653WyWEijLXAHfAgvwU9QJqYRb4OHoc4Sz4jPwc4oxqgn2nkh6++10frOOvdoWPXTGXUIHoQ6D5wg/g5/B9TCibof6GHvraA9YSW89JVqGu6w0YbiKrsVY7Rh1a/kyA/A+fA5fAx1r65ndpnoJb8H6rr/mfg61PmBsBLFGPVEK9ew4Q4bbSiuslvtqlfNHmLApXAUnoe3oepdV/+5ZIbhvmDvVeKXMAZe+hhLddrYaB1bMW2LMVqj6lXFul4PIkF36TeI9UbuE7GqXkOvIaOnAJ0xVOlnyMdc5WnYKsaoJ6oFy0cbzedSI9Wo+k30OAlVvw+Ij8Kw3km0VPv9bPTBL/AmfALj4aWPdxXX0kbjPMW3KsZoVNXP5MBPwcXwBzwOX0HVOGFLdwV6S7+flDJqeY3MVzWNZjFGPdHoNY1saKORoqKbRVX9AMNthOowSrwCroJ6g6ezgX6pHyS/GaqXal9P+non8Ia96hWeN0i3wUvfpiPDho1mkNg2RDFGVY5tcw839OS+PUipopU/RP4InAr1nD49yOg+QRWtfB97VfVviX9CVz0aJgzFfEc90dzfiS5VL+EX+dTVsB8ugrqHn0Os67iqXmcAPfuzs6XqPs3GBfgBxtS7RvDSy0M+2mg+l4V9R1WslYev3bqy6wShv7FRh2X8p7zOAANkDsIF8CPcBe9DVTphDfg7WkNWVFMbjdJUo1ExRrtc63XXrToVw7dw7wMjOuINZOZDPekPE9+FuhMgrI1ijHqitde2Swcb7SKo9u4u1/r48XQ//4gOK+BTuBW+gSnw0qfYG6+vjY5nJSVXjNEu1/p4Bztpujzo8Jp4JMikhMUY9URTlnm8vjY6npWUXIaq17u7vcxCTwR6z693gCl39eGBeelDGzliG81hMRyjGKNJVa+j1PW9n8PXL+/fie+EQpLjYox6oslrPWYAGx0jJHkzqeqX8PHH4DqoBdK1PtdVXsfopZeHfLTRfC4L+442rHq9BOzlYNdDxfom6e39O/JVta8R9EQgZ53p72hnP/X32mh9Z517FGO0YdWrWp8iQXfya4mVv0f8IsgQtiG+3tWtGKOeaNs6Z9iw0QwS24bI8MvdbAbUX93r3v4Kmc9tH5S64aVPNTi2v42ONZK6XYzR1AN1fxuwARuwARuwgf/bwF+EMnfBJv4+AwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding = autoencoder.decode(encoding)\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ved √• ha en flaskehals i midten av nettverket, har modellen l√¶rt seg en lav-dimensjonell representasjon av sifrene.\n",
    "\n",
    "Det morsomme er at decoder-delen av nettverket kan anvendes som en generativ modell. Inputtet vil v√¶re en vektor av lav dimensjon. Vi har ogs√• brukt `Tanh` som aktiveringsfunksjon p√• output fra encoderen, som betyr at decoderen alltid vil forvente tall som ligger i $\\langle-1, 1\\rangle$. \n",
    "\n",
    "Hvis vi generer en 16-dimensjonal vektor med tilfeldige tall, og bruker dette som input til decoderen, f√•r vi et _syntetisk_ siffer som output. Den 16-dimensjonale vektoren vil i faglitteraturen kalles for en _latent_ representasjon av et siffer.\n",
    "\n",
    "Jeg skrev [masteroppgaven min](https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/3095628) om latente representasjoner i diffusjonsmodeller. Bare ta en titt üòÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAAEwElEQVR4Ae2bu2sVQRSHr8ZHJA8txBBFA0ogKmIhaQ0iItgIiiBEIVgkoG3QQvFPUGttxM5GC9Moio9GLYwpNBAVDIL4RhOCb6Pw/VLMunfvnb07NzrkWHz37Jkzj/3NPTszm2upZP9MAVNgbikwb/Zvt4Euf+XseH7O+H8WbgMNLb0pGlrRBaEb/Ls9Tdk0bj1iFmGvhpPwNawMm/rK+uQvNUXza1a5RjSK1nGtV9NSQuv7CkTbB9vhCLwG38MsRKOoDTRrCmv1m6K1KpdVry5rfQu9dcBeuA2ugj9gK3wFFX8e+xtMw6Y+rUkxjylaTL907WgUDZz1jUixCx6H66B29ZglneiV+1r9t1JwDz6CilG8GI2iNlB32kLYpmgIFd02gmW9pmYPbZ+By6CgFXySi2b4G+ppsBl7OdS6r0i9DcBdUvuy/2vaQENPjykaWtEyWa/zuLLSv7tDhJ6Gi6He0fVj34TCSj4G4V7o7up/4nHzHYdlvWQISEumgGLSVDSKBnib18YdP4ZN8ATUEyCdv+pyAzE3oDDAxxC0Hb4jTJ3MaL6jNtDQ34Aya71/F5qOo1TQznwU+xTM2i3IP+XU0hl/DE8633HbWi8ZAtKSKaCYNBWNojNZr/Eqcyc8xNB63UVkn3PH17Gz8p3CGRzkU+d67erH3eKUHY2iNtDU3BV0mKIFBUxVn8l67cMnU8VZDuX1OMUjsBt2Qj0TsnJfp/7DRCrmIrZ7useRgE19Qo4AF6ZoABETTUSjaGKHn5WniVtzLj5j74b98C3Mynrl+zlilkC98TuJXbn3aBS1gTKbAWGKBhSTppSgAVrV42MhLX1JtafSh/jXwq9Q7/BvY1vWI8OswZIptNTRKJpY64uooLO5mG7nLq6NUDGD2D75rtaiUdQGqgkLR1M0nJZqKbHWN+Jzz9eV11+fwfQSdAGqs2fY62HWG3sKE7CpT8gR4MIUDSBiooloFE1kvW5Bu3S93xMVpCeA/3NgE80NQ/3vG+3qu/C8UGfejEZRG6j3nHoGmqKeQnmHldnht1P5DdT7tzXYO2APPAbHYBrNuB5A5bueFQfw5M13tW9TLx3C0RQNp2Vk39Eya30bt/AJat3vxr4EW6HO5vuxh6Aa0r79Dp4WKCjTO7nQb3KcQi/TvqNeMuUIMkVziOUVGo2iiax3F36duJX1yvRh7ly/otfa/Q6PbEVqldcOQU1PE3MEnnXiMXMgGkVtoDlm1SvUFPWSKUeQm+glreDKVuXyd5r6CHvgFahTgDJama5f2amunhiarCni70O3ZRw5YFOfQyyvUFPUS6YcQdEomsh63aDy3b1ZZfFzXFvgdtgBP0D9PqcPeyfUXwRGsSeg9gB6p5fuhZBMRKOoDTRzDmssMEVrFC6zmpbfzOK8BToLDFBNT4Zb2FfhE6gu9bs+7RZwV4FNfRWBcheborklq1IhGkXLrPVVbq1isfbzl4l5CnXef4mtE8RSx27A1uqvHQWOMohGURtomdkr5DJFC8lXpnLgtV49aJqauNCbAeW7SrXz98l0d7w29a4aIWxTNISKbhvRKFqXrHeVSNta3yuv7Ola0ShqA01PXjGPKVpMP6ttCpgCpoApYAqYAnNNgT8RW5WTh/iLiAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent = (torch.rand(size=(1, autoencoder.bottleneck_size))-0.5)*2\n",
    "decoding = autoencoder.decode(latent.to(device))\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultatene gjenspeiler den enkle arkitekturen som er valgt, og f√•tallet epoker den fikk trene."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
